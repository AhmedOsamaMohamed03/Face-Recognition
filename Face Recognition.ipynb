{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dddf3f-ed7a-45b5-94d7-5afab9592953",
   "metadata": {},
   "source": [
    "# Pattern Recognition Course\n",
    "## Lab 2: Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45906b18-8f9b-407c-9410-5a56a4fc6f54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427505e3-bf1d-49fb-a450-941c32b06e00",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6fec9-a902-43eb-b7ce-b868256d40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from math import log2\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456dc1e1-1663-4e82-af2c-ab11495824a8",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825cc45-5928-4469-b9e2-a7f9690a9809",
   "metadata": {},
   "source": [
    "- ### Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7501d4-b7ae-4c2c-88ed-01cea8628e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kasikrit/att-database-of-faces\")\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each subject folder (s1 to s40)\n",
    "for subject in sorted(os.listdir(path)):\n",
    "    subject_path = os.path.join(path, subject)\n",
    "    \n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(subject_path):\n",
    "        continue\n",
    "\n",
    "    # Get the subject number from folder name (s1 -> 0, s2 -> 1, etc.)\n",
    "    subject_num = int(subject[1:]) - 1\n",
    "    \n",
    "    # Loop through each image in the subject folder\n",
    "    for image_file in sorted(os.listdir(subject_path)):\n",
    "        if image_file.endswith('.pgm'):  # AT&T uses PGM format\n",
    "            image_path = os.path.join(subject_path, image_file)\n",
    "            \n",
    "            # Open and convert to numpy array\n",
    "            img = Image.open(image_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            images.append(img_array)\n",
    "            labels.append(subject_num)\n",
    "\n",
    "images, labels = np.array(images), np.array(labels)\n",
    "\n",
    "print(f\"Dataset loaded with {len(images)} images\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81eb38-d645-431e-b649-fea1cf5be98a",
   "metadata": {},
   "source": [
    "- ### Generate the Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0867f-f0b9-4375-b0d8-fb82794491db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of pixels (features) for each image\n",
    "row_pixels, col_pixels = images[0].shape\n",
    "pixels_number = row_pixels * col_pixels\n",
    "\n",
    "# Initialize data matrix and target vector\n",
    "X = np.ndarray((len(images), pixels_number))\n",
    "y = np.array(labels)\n",
    "\n",
    "# Fill the data matrix\n",
    "for i, img in enumerate(images):\n",
    "    X[i] = img.flatten()\n",
    "\n",
    "print(f'Data Matrix Shape{X.shape}')\n",
    "print(f'Target Vector Length {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e009998-50d9-45c2-96b9-59cc752d92ee",
   "metadata": {},
   "source": [
    "- ### Generate Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342f7e6-07b1-4b72-84e8-e985964d4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even rows for testing, Odds for training\n",
    "X_train, X_test = X[1::2], X[::2]\n",
    "y_train, y_test = y[1::2], y[::2]\n",
    "print(f'Training Set Matrix Shape {X_train.shape}, Training Labels Length {y_train.shape}')\n",
    "print(f'Test Set Matrix Shape {X_test.shape}, Test Labels Length {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa68807-009b-40e2-9e79-bec73c8b6389",
   "metadata": {},
   "source": [
    "## PCA Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66224d61-c18b-417a-9cbb-417dd6689a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
